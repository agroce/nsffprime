\section{Related Work}

This project builds on and integrates prior work in fuzzing, symbolic execution, runtime specification
checking, and mutation analysis, with a particular emphasis on leveraging structural information provided
by software frameworks. While each of these areas has an extensive literature, existing techniques
generally treat programs as unstructured artifacts and fail to exploit the semantic constraints imposed
by embedded systems frameworks.

\paragraph{Test Harness Generation (classical and LLM-assisted).}
Automating the construction of test and fuzzing harnesses has received increasing attention because
manual harness creation is a major impediment to large-scale unit
fuzzing.  Recent work explores fully automated harness synthesis from unit tests, API usage, or consumer code, and
introduces semantics-preserving oracle checks to validate generated harnesses \cite{oracle2025}.
Other systems mine real-world API usage to synthesize harnesses that reflect realistic call sequences
and data shapes \cite{wildsync2025,bindle2023}.  To our knowledge, no
work looks to use framework (embedded or other framework), rather than
simply language level, semantics to
enhance harness generation, or to incorporate harness generation into
a framework's existing test workflow.  While developers are
at least familliar with writing unit tests, a widely studied use of LLMs, few have experience in
writing property-based tests or fuzzing harnesses~\cite{goldstein2022some}, a different task
that is often perceived as very difficult.  Generalizing oracle
generation from specific to parameterized unit tests is a potential
long-term solution to this problem, and there is already work underway
to generate fuzz drivers using LLMs~\cite{zhang2023understanding},
including by Google's OSS-Fuzz team, one of the most important
industrial fuzzing efforts~\cite{ossfuzzllm}.  However, such methods are not at present repeatable and
consistent, making them ill-suited for running repeatedly as part of a framework
workflow, where expectations of consistency and predictability are
critical.  They are currently best suited for one-time generation of a
human-modified and maintained harness.  To our knowledge, no previous
work has aimed to produce harnesses that, via a tool-agnostic layer
such as DeepState, apply to fuzzing, symbolic execution, and bounded
or explicit-state model checking.

\paragraph{Fuzzing and Hybrid Test Generation.}
Coverage-guided fuzzing has proven highly effective at discovering bugs in systems software, particularly
when augmented with feedback mechanisms such as coverage metrics and path prioritization
\cite{aflfast}. Hybrid approaches combine fuzzing with symbolic or concolic execution to improve
path exploration, especially for hard-to-reach code regions \cite{zhao2019send}. However, these
techniques typically operate on binaries or APIs with minimal semantic context, requiring substantial
manual effort to construct effective harnesses. In contrast, this proposal leverages framework models
to automatically generate semantically valid harnesses and guide exploration toward architecturally
meaningful behaviors.

\paragraph{Unit-Level Symbolic Execution and Property-Based Testing.}
Property-based testing tools such as Hypothesis and PropEr demonstrate the effectiveness of randomized,
specification-driven testing at the unit level \cite{Hypothesis,PROPER}. DeepState extends this paradigm
to C and C++ by providing a unit-test–like interface compatible with fuzzing, symbolic execution, and
model checking backends \cite{DeepState,DeepStateTutorial}. Prior work has shown that DeepState can
expose subtle bugs in complex systems code, but harness creation and specification remain largely manual.
The present work extends DeepState by automatically deriving both harnesses and specifications from
framework-level artifacts.

\paragraph{Runtime Specification and Modifies-Clause Checking.}
Design-by-contract approaches, originating in Eiffel and Larch, integrate executable specifications such
as preconditions, postconditions, and modifies clauses into program development
\cite{Meyer1997OOSC,GuttagHorningWing1985Larch}. Modern verified languages such as Dafny provide
strong automated support for such specifications \cite{Dafny}, but these techniques are rarely adopted
in embedded C/C++ systems due to tooling and performance constraints. Prior work demonstrated that
modifies clauses can be dynamically checked for C programs, even in the context of explicit-state
model checking. This proposal extends that line of work by using LLVM-based instrumentation and
framework-derived memory models to make modifies-clause checking practical for modern embedded
systems.

\paragraph{Mutation Analysis and Test Adequacy.}
Mutation testing has long been used to assess test suite effectiveness, but traditional mutation operators
are largely syntactic and language-specific. Empirical studies have examined the relationship between
mutation scores and real faults \cite{GopinathMutants,ahmed_testedness}, while more recent work has
explored the interaction between fuzzing and mutation testing \cite{fuzzing22,seip2022}. The
\texttt{universalmutator} framework was designed to address the limitations of grammar-bound mutation
tools by enabling domain-specific mutation definitions independent of programming language syntax.
This proposal builds directly on that foundation to introduce \emph{framework-aware mutation operators}
that better reflect the fault models of embedded systems.

\paragraph{Framework-Aware and Model-Based Testing.}
Model-based testing tools generate tests from explicit behavioral models but typically treat the
implementation as a black box, requiring redundant modeling effort and offering limited integration
with implementation-level testing. Recent work on firmware re-hosting and hardware–software boundary
fuzzing demonstrates the value of abstraction-aware testing \cite{halucinator,song2019periscope}, but
these approaches do not exploit the rich semantic structure already present in component-based
frameworks. In contrast, this project treats the framework itself as the model, enabling a unified
approach to fuzzing, specification checking, and mutation analysis without requiring additional
developer effort.

In summary, prior work has addressed fuzzing, specification checking, and mutation testing largely in
isolation. This project is the first to systematically integrate these techniques by exploiting the
semantic infrastructure of an embedded systems framework, enabling more effective automated
assurance with lower cost and greater developer adoption.
