
Mutation analysis provides a quantitative measure of test adequacy by introducing small, syntactic changes (which are likely to change the semantics for the worst, thus serve as ``artificial bugs'') into a program and evaluating whether the existing tests detect the injected faults.
Traditional mutation testing tools operate primarily at the source level, applying generic syntactic
operators such as arithmetic replacement, logical negation, or constant modification. While effective
for many domains, such operators do not reflect important fault classes in embedded systems
frameworks, where a substantial fragment of the system’s semantics resides in architectural structure rather than in
individual expressions.

In frameworks such as FPrime, consequential defects often arise from subtle deviations in
configuration or interaction patterns: mis-wired ports, altered queue depths, changed command or
telemetry dictionaries, or incorrect initialization sequencing. These errors are difficult to express
using conventional mutation operators but correspond closely to real failures observed in deployed
embedded systems. This motivates the development of \emph{framework-aware mutation operators},
whose semantics align with the abstractions imposed by the framework itself.

The PI is the creator of \texttt{universalmutator}, a language-agnostic mutation engine designed
explicitly to support customizable, domain-specific mutation operators~\cite{FSE24UM}. \texttt{universalmutator}
has been successfully used to generate mutants across a wide range of programming languages and
domains, demonstrating that mutation operators need not be tied to a specific grammar or compiler
front end. This flexibility makes \texttt{universalmutator} an ideal platform for implementing
framework-aware mutation operators for FPrime.

Using \texttt{universalmutator} as the substrate, we will define mutation operators that act on
framework-relevant artifacts, in both source code and at the FPP level, including, for example:
\begin{itemize}
  \item \textbf{Port-level mutations:} swapping or removing connections, altering compatible port
        types, modifying queue sizes or drop policies for asynchronous ports.
  \item \textbf{Topology mutations:} re-routing data flow, perturbing component startup order, or
        replacing active components with passive equivalents.
  \item \textbf{Command and telemetry mutations:} modifying opcode assignments, parameter ranges,
        or enumeration definitions in command and telemetry dictionaries.
  \item \textbf{Resource mutations:} altering buffer capacities and allocation patterns to expose
        hidden assumptions about resource sufficiency.
\end{itemize}

Because these mutations operate at the same abstraction level as the developer’s design intent, they
model realistic error modes that are not captured by traditional syntactic mutants. Framework-aware mutation
analysis thus serves two complementary purposes. First, it provides a meaningful measure of the
adequacy of both developer-written and automatically generated DeepState tests. Second, surviving
mutants often indicate implicit or underspecified architectural assumptions, guiding developers
toward clearer specifications and stronger framework usage.

By building on \texttt{universalmutator}, this project leverages a mature and extensible mutation
infrastructure, minimizing engineering effort while enabling expressive and precise mutation
definitions for each embedded system framework, including at minimum FPrime and AUTOSAR (for this portion of the project, where less effort is required to integrate with a framework, we intend to implement and apply our techniques to at least one framework in addition to FPrime, and apply it to multiple realworld AUTOSAR examples with existing tests). The result will be the first mutation testing approach that operates natively at the level
of an embedded systems framework, rather than treating framework-generated code as unstructured
source.  It is unclear how important such mutations are; in the past, the difficulty of incorporating custom mutants
that target semantic levels other than the core programming language has generally been too large to encourage study of the utility of such mutants.  One of our
goals is to determine how often such mutants capture test weaknesses that are not detected by more traditional mutants.
